import os
import sys
from openai import OpenAI
from dotenv import load_dotenv

# Ajouter le dossier parent au systÃ¨me pour trouver le dossier 'src'
root_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(root_path)

# Charger le .env depuis la racine
load_dotenv(os.path.join(root_path, ".env"))

client = OpenAI(
    base_url="https://models.inference.ai.azure.com",
    api_key=os.getenv("GITHUB_TOKEN")
)

# Initialisation de l'historique des messages
messages = [
    {"role": "system", "content": "Tu es un assistant utile et poli."}
]

print("ğŸ’¬ Chat AI dÃ©marrÃ© (tapez 'exit' ou 'quit' pour quitter)")

while True:
    user_input = input("\nğŸ‘¤ Vous : ")
    
    if user_input.lower() in ["exit", "quit"]:
        print("Fin de la session. Au revoir !")
        break
        
    if not user_input.strip():
        continue

    # Ajouter le message de l'utilisateur Ã  l'historique
    messages.append({"role": "user", "content": user_input})

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages
        )

        ai_message = response.choices[0].message.content
        print(f"\nğŸ¤– IA : {ai_message}")

        # Ajouter la rÃ©ponse de l'IA Ã  l'historique pour maintenir le contexte
        messages.append({"role": "assistant", "content": ai_message})
        
    except Exception as e:
        print(f"\nâŒ Erreur : {e}")
